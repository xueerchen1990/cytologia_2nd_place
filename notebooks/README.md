# Running the `inference_local.ipynb` with GPU Support

Follow the steps below to get started:

## Step 1: Download the Input Files

1. Download the `input.zip` file from [Google Drive](https://drive.google.com/file/d/1uLKK_wS22yEcNWgh2zeLeaChm4vZQhU3/view?usp=sharing).
2. Place the `input.zip` file in the **same folder** as the `inference_local.ipynb` file.

## Step 2: Extract the Input Data

1. After downloading, unzip the `input.zip` file by `unzip input.zip`.
2. This will create a folder named **`input`** containing the required data.

### Folder Structure

After downloading and unzipping the file, your directory should look like this:

```
/your-project-folder/
  ├── inference_local.ipynb
  ├── input.zip
  └── input/                # Folder created after unzipping input.zip
```

## Step 3: Run the `inference_local.ipynb` Notebook

1. Open the `inference_local.ipynb` notebook in your preferred Jupyter environment (e.g., Jupyter Notebook, JupyterLab, or Google Colab).
2. **Ensure that you have an NVIDIA GPU** available for optimal performance.
3. Execute the notebook cells in sequence to perform inference.


