{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-UQE1_ydlCX",
    "outputId": "1547cde2-2703-4581-b374-2890e9ff5c9d"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVopogb1NQgk",
    "outputId": "027adce9-278f-4224-f372-81c79f5144a8"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics==8.3.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgB1L97P7mHi"
   },
   "outputs": [],
   "source": [
    "data_path = './input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsgpkF8SMrHz",
    "outputId": "18705e02-d358-4a3b-a851-c7f6bcfa7cd1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from ultralytics.utils import LOGGER\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.models.yolo.detect import DetectionPredictor\n",
    "from ultralytics.engine.results import Results\n",
    "from ultralytics.utils import ops\n",
    "from random import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'{data_path}/scripts')\n",
    "from metrics import compute_cytologia_metric_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cy4ddgYcdCy"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def load_image(img_path):\n",
    "    with Image.open(img_path) as img:\n",
    "        imgx = img.copy()\n",
    "    return imgx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfpUhcvicnhB"
   },
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv(os.path.join(data_path, 'test.csv'))\n",
    "img_folder = os.path.join(data_path, 'test_images')\n",
    "for _,row in test.iterrows():\n",
    "    imgpath = row['NAME']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img = load_image(os.path.join(img_folder, imgpath))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_V-Bgmoh5r9"
   },
   "outputs": [],
   "source": [
    "def my_non_max_suppression(\n",
    "    prediction,\n",
    "    conf_thres=0.25,\n",
    "    iou_thres=0.45,\n",
    "    classes=None,\n",
    "    agnostic=False,\n",
    "    multi_label=False,\n",
    "    labels=(),\n",
    "    max_det=300,\n",
    "    nc=0,  # number of classes (optional)\n",
    "    max_time_img=0.05,\n",
    "    max_nms=30000,\n",
    "    max_wh=7680,\n",
    "    in_place=True,\n",
    "    rotated=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform non-maximum suppression (NMS) on a set of boxes, with support for masks and multiple labels per box.\n",
    "\n",
    "    Args:\n",
    "        prediction (torch.Tensor): A tensor of shape (batch_size, num_classes + 4 + num_masks, num_boxes)\n",
    "            containing the predicted boxes, classes, and masks. The tensor should be in the format\n",
    "            output by a model, such as YOLO.\n",
    "        conf_thres (float): The confidence threshold below which boxes will be filtered out.\n",
    "            Valid values are between 0.0 and 1.0.\n",
    "        iou_thres (float): The IoU threshold below which boxes will be filtered out during NMS.\n",
    "            Valid values are between 0.0 and 1.0.\n",
    "        classes (List[int]): A list of class indices to consider. If None, all classes will be considered.\n",
    "        agnostic (bool): If True, the model is agnostic to the number of classes, and all\n",
    "            classes will be considered as one.\n",
    "        multi_label (bool): If True, each box may have multiple labels.\n",
    "        labels (List[List[Union[int, float, torch.Tensor]]]): A list of lists, where each inner\n",
    "            list contains the apriori labels for a given image. The list should be in the format\n",
    "            output by a dataloader, with each label being a tuple of (class_index, x1, y1, x2, y2).\n",
    "        max_det (int): The maximum number of boxes to keep after NMS.\n",
    "        nc (int, optional): The number of classes output by the model. Any indices after this will be considered masks.\n",
    "        max_time_img (float): The maximum time (seconds) for processing one image.\n",
    "        max_nms (int): The maximum number of boxes into torchvision.ops.nms().\n",
    "        max_wh (int): The maximum box width and height in pixels.\n",
    "        in_place (bool): If True, the input prediction tensor will be modified in place.\n",
    "        rotated (bool): If Oriented Bounding Boxes (OBB) are being passed for NMS.\n",
    "\n",
    "    Returns:\n",
    "        (List[torch.Tensor]): A list of length batch_size, where each element is a tensor of\n",
    "            shape (num_boxes, 6 + num_masks + num_classes) containing the kept boxes, with columns\n",
    "            (x1, y1, x2, y2, confidence, class, mask1, mask2, ..., all class probabilities).\n",
    "    \"\"\"\n",
    "\n",
    "    # Checks\n",
    "    assert 0 <= conf_thres <= 1, f\"Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0\"\n",
    "    assert 0 <= iou_thres <= 1, f\"Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0\"\n",
    "    if isinstance(prediction, (list, tuple)):  # YOLOv8 model in validation model, output = (inference_out, loss_out)\n",
    "        prediction = prediction[0]  # select only inference output\n",
    "    if classes is not None:\n",
    "        classes = torch.tensor(classes, device=prediction.device)\n",
    "\n",
    "    if prediction.shape[-1] == 6:  # end-to-end model (BNC, i.e. 1,300,6)\n",
    "        output = [pred[pred[:, 4] > conf_thres][:max_det] for pred in prediction]\n",
    "        if classes is not None:\n",
    "            output = [pred[(pred[:, 5:6] == classes).any(1)] for pred in output]\n",
    "        return output\n",
    "\n",
    "    bs = prediction.shape[0]  # batch size (BCN, i.e. 1,84,6300)\n",
    "    nc = nc or (prediction.shape[1] - 4)  # number of classes\n",
    "    nm = prediction.shape[1] - nc - 4  # number of masks\n",
    "    mi = 4 + nc  # mask start index\n",
    "    xc = prediction[:, 4:mi].amax(1) > conf_thres  # candidates\n",
    "\n",
    "    # Settings\n",
    "    # min_wh = 2  # (pixels) minimum box width and height\n",
    "    time_limit = 2.0 + max_time_img * bs  # seconds to quit after\n",
    "    multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "\n",
    "    prediction = prediction.transpose(-1, -2)  # shape(1,84,6300) to shape(1,6300,84)\n",
    "    if not rotated:\n",
    "        if in_place:\n",
    "            prediction[..., :4] = ops.xywh2xyxy(prediction[..., :4])  # xywh to xyxy\n",
    "        else:\n",
    "            prediction = torch.cat((ops.xywh2xyxy(prediction[..., :4]), prediction[..., 4:]), dim=-1)  # xywh to xyxy\n",
    "\n",
    "    t = time.time()\n",
    "    output = [torch.zeros((0, 6 + nm + nc), device=prediction.device)] * bs\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        # Apply constraints\n",
    "        # x[((x[:, 2:4] < min_wh) | (x[:, 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "        x = x[xc[xi]]  # confidence\n",
    "\n",
    "        # Cat apriori labels if autolabelling\n",
    "        if labels and len(labels[xi]) and not rotated:\n",
    "            lb = labels[xi]\n",
    "            v = torch.zeros((len(lb), nc + nm + 4), device=x.device)\n",
    "            v[:, :4] = ops.xywh2xyxy(lb[:, 1:5])  # box\n",
    "            v[range(len(lb)), lb[:, 0].long() + 4] = 1.0  # cls\n",
    "            x = torch.cat((x, v), 0)\n",
    "\n",
    "        # If none remain process next image\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Detections matrix nx6 (xyxy, conf, cls)\n",
    "        box, cls, mask = x.split((4, nc, nm), 1)\n",
    "        # Store all class probabilities\n",
    "        all_cls_probs = cls\n",
    "\n",
    "        if multi_label:\n",
    "            i, j = torch.where(cls > conf_thres)\n",
    "            x = torch.cat((box[i], x[i, 4 + j, None], j[:, None].float(), mask[i]), 1)\n",
    "        else:  # best class only\n",
    "            conf, j = cls.max(1, keepdim=True)\n",
    "            x = torch.cat((box, conf, j.float(), mask), 1)[conf.view(-1) > conf_thres]\n",
    "\n",
    "        # Filter by class\n",
    "        if classes is not None:\n",
    "            x = x[(x[:, 5:6] == classes).any(1)]\n",
    "\n",
    "        # Check shape\n",
    "        n = x.shape[0]  # number of boxes\n",
    "        if not n:  # no boxes\n",
    "            continue\n",
    "        if n > max_nms:  # excess boxes\n",
    "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence and remove excess boxes\n",
    "\n",
    "        # Batched NMS\n",
    "        c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
    "        scores = x[:, 4]  # scores\n",
    "        if rotated:\n",
    "            boxes = torch.cat((x[:, :2] + c, x[:, 2:4], x[:, -1:]), dim=-1)  # xywhr\n",
    "            i = ops.nms_rotated(boxes, scores, iou_thres)\n",
    "        else:\n",
    "            boxes = x[:, :4] + c  # boxes (offset by class)\n",
    "            i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "        i = i[:max_det]  # limit detections\n",
    "\n",
    "        output[xi] = torch.cat((x[i], all_cls_probs[i]), dim=1)\n",
    "\n",
    "        if (time.time() - t) > time_limit:\n",
    "            LOGGER.warning(f\"WARNING ⚠️ NMS time limit {time_limit:.3f}s exceeded\")\n",
    "            break  # time limit exceeded\n",
    "\n",
    "    return output\n",
    "\n",
    "class MyCustomPredictor(DetectionPredictor):\n",
    "\n",
    "    def postprocess(self, preds, img, orig_imgs):\n",
    "        \"\"\"Post-processes predictions and returns a list of Results objects.\"\"\"\n",
    "        preds = my_non_max_suppression(\n",
    "            preds,\n",
    "            self.args.conf,\n",
    "            self.args.iou,\n",
    "            agnostic=self.args.agnostic_nms,\n",
    "            max_det=self.args.max_det,\n",
    "            classes=self.args.classes,\n",
    "        )\n",
    "\n",
    "        if not isinstance(orig_imgs, list):  # input images are a torch.Tensor, not a list\n",
    "            orig_imgs = ops.convert_torch2numpy_batch(orig_imgs)\n",
    "\n",
    "        results = []\n",
    "        probs = []\n",
    "        for pred, orig_img, img_path in zip(preds, orig_imgs, self.batch[0]):\n",
    "            pred,prob = pred[:,:-23], pred[:,-23:]\n",
    "            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape)\n",
    "            results.append(Results(orig_img, path=img_path, names=self.model.names, boxes=pred))\n",
    "            if len(prob):\n",
    "                probs.append(prob.cpu().numpy()[0])\n",
    "        self.probs.extend(probs)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d4gy6xUycUv"
   },
   "outputs": [],
   "source": [
    "def predict_det(df, model, aug, batch_size=1, max_det=11):\n",
    "\n",
    "    # Get model output names for later use\n",
    "    for _,row in df.iterrows():\n",
    "        img_name = row['NAME']\n",
    "    img = load_image(os.path.join(img_folder, img_name))\n",
    "    res = model(img, verbose=False, augment=aug)\n",
    "    names = res[0].names\n",
    "\n",
    "    my_predictor = MyCustomPredictor()\n",
    "    my_predictor.args = model.predictor.args\n",
    "    my_predictor.probs = []\n",
    "    model.predictor = my_predictor\n",
    "\n",
    "    def dec(x):\n",
    "        return [float(f'{i:.3f}') for i in x]\n",
    "\n",
    "    outs = []\n",
    "    test_probs = []\n",
    "    # Use tqdm with total number of images\n",
    "    with tqdm(total=df.shape[0], desc=\"Processing images\") as pbar:\n",
    "        for i in range(0, df.shape[0], batch_size):\n",
    "            batch_rows = df.iloc[i: i + batch_size]\n",
    "            #imgs = [Image.fromarray(images_array[i]) for i in batch_rows['imgid']]\n",
    "            imgs = [load_image(os.path.join(img_folder, i)) for i in batch_rows['NAME']]\n",
    "            results = model(imgs, max_det=max_det, verbose=False, augment=aug)\n",
    "\n",
    "            for j, (_, row) in enumerate(batch_rows.iterrows()):\n",
    "                result = results[j]\n",
    "                xyxys = result.boxes.xyxy.cpu().numpy().tolist()\n",
    "                clss = result.boxes.cls.cpu().numpy().tolist()\n",
    "                ids = tids[row['NAME']]\n",
    "                probs = my_predictor.probs[j]\n",
    "                for c, idx in enumerate(ids):\n",
    "                    if c < len(clss):\n",
    "                        x1, y1, x2, y2 = dec(xyxys[c])\n",
    "                        cls_id = int(clss[c])\n",
    "                        cls = names[cls_id]\n",
    "                        outs.append([idx, row['NAME'], x1, y1, x2, y2, cls])\n",
    "                    elif max_det > 1:\n",
    "                        # copy last prediction but avoid exact duplication\n",
    "                        outs.append([idx, row['NAME'], x1+random()*1e-5, y1, x2, y2, cls])\n",
    "                    if batch_size == 1:\n",
    "                        if len(outs) == len(my_predictor.probs)+1:\n",
    "                            tmp = np.zeros(23)\n",
    "                            tmp[cls_id] = 1\n",
    "                            my_predictor.probs.append(tmp)\n",
    "                        elif len(outs) != len(my_predictor.probs):\n",
    "                            assert 0\n",
    "                pbar.update(1)  # Update progress bar for each image\n",
    "            assert len(outs) == len(my_predictor.probs)\n",
    "\n",
    "    sub = pd.DataFrame(outs, columns=['trustii_id', 'NAME', 'x1', 'y1', 'x2', 'y2', 'class'])\n",
    "    probs = np.array(my_predictor.probs)\n",
    "    return sub, probs, names\n",
    "\n",
    "def predict_cls(test, model, batch_size=32):\n",
    "    \"\"\"\n",
    "    Predicts the class of images in a DataFrame using a given model with batched inference.\n",
    "\n",
    "    Args:\n",
    "        test: DataFrame containing image names, bounding box coordinates, and image IDs.\n",
    "        model: The model used for prediction.\n",
    "        batch_size: The batch size for inference.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with predicted class and probabilities for each class.\n",
    "    \"\"\"\n",
    "    cls_res = []\n",
    "    probs = []\n",
    "    for i in tqdm(range(0, test.shape[0], batch_size)):\n",
    "        batch = test.iloc[i:i + batch_size]\n",
    "        imgs = []\n",
    "        for c, row in batch.iterrows():\n",
    "            img = load_image(os.path.join(img_folder, row['NAME']))\n",
    "            imgs.append(img)\n",
    "\n",
    "        res = model(imgs, verbose=False)\n",
    "\n",
    "        batch_probs = []\n",
    "        batch_cls = []\n",
    "\n",
    "        for r in res:\n",
    "            pt = r.probs.data.cpu().numpy()\n",
    "            batch_probs.append(pt)\n",
    "            batch_cls.append(r.names[pt.argmax()])\n",
    "\n",
    "        probs.extend(batch_probs)\n",
    "        cls_res.extend(batch_cls)\n",
    "\n",
    "    probs = np.array(probs)\n",
    "    test['class'] = cls_res\n",
    "    for k, v in res[0].names.items():\n",
    "        test[v] = probs[:, k]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JhxO640d7FMz",
    "outputId": "b8169ee9-182d-4019-d8bd-dda10d5948ee"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "aug = True\n",
    "fold = 0\n",
    "subs = []\n",
    "\n",
    "test = pd.read_csv(f'{data_path}/test.csv')\n",
    "test['bbox_count'] = test.groupby('NAME')['NAME'].transform('count')\n",
    "test1 = test[test.bbox_count==1]\n",
    "# img_dir = '{data_path}/images'\n",
    "# print(img_dir)\n",
    "# get predictions\n",
    "\n",
    "tids = test.groupby('NAME')['trustii_id'].agg(list).to_dict()\n",
    "df = test.groupby('NAME').agg({'trustii_id':'count'})\n",
    "df.columns = ['bbox_count']\n",
    "df = df.reset_index()\n",
    "assert df.shape[0] == len(os.listdir(img_folder))\n",
    "mask = df.bbox_count == 1\n",
    "df1 = df[mask]#[:100]\n",
    "df2 = df[~mask]#[:100]\n",
    "\n",
    "# mt = test1.NAME.isin(df1.NAME) #| test1.NAME.isin(df2.NAME)\n",
    "# test1 = test1[mt]\n",
    "\n",
    "backup = []\n",
    "for fold in range(4):\n",
    "    det_model = YOLO(f'{data_path}/models/aug1/fold_{fold}_best.pt')\n",
    "    print('aug1', f'fold {fold}')\n",
    "    #sub2, probs2, names = predict_no_prob(df2, det_model, aug, test_imgs_array)\n",
    "    sub2, probs2, names = predict_det(df2, det_model, aug, batch_size=1, max_det=11)\n",
    "    print(sub2.shape, \"should be 3316\")\n",
    "    sub1, probs1, names = predict_det(df1, det_model, aug, batch_size=32, max_det=1)\n",
    "    print(sub1.shape, df1.shape)\n",
    "    sub1.shape[0]+sub2.shape[0], test.shape[0]\n",
    "\n",
    "    df3 = df1[~df1.NAME.isin(sub1.NAME)]\n",
    "    if df3.shape[0]:\n",
    "        sub3 = sub1[:df3.shape[0]].copy()\n",
    "        sub3['NAME'] = df3['NAME'].values\n",
    "        sub3['trustii_id'] = sub3['NAME'].apply(lambda x: tids[x][0])\n",
    "        probs3 = np.zeros((df3.shape[0], probs2.shape[1]))\n",
    "        sub = pd.concat([sub1,sub2,sub3])\n",
    "        probs = np.vstack([probs1, probs2, probs3])\n",
    "    else:\n",
    "        sub = pd.concat([sub1,sub2])\n",
    "        probs = np.vstack([probs1, probs2])\n",
    "\n",
    "    for k,v in names.items():\n",
    "        sub[v] = probs[:,k]\n",
    "        # only keep 5 decimal places\n",
    "        sub[v] = sub[v].round(5)\n",
    "    sub = test[['trustii_id']].merge(sub, on='trustii_id', how='left')\n",
    "    subs.append(sub)\n",
    "    backup.append(sub.copy())\n",
    "\n",
    "df1 = df1.merge(subs[0],on='NAME',how='left')\n",
    "for model_name in ['crop','rotate','rotate50']:\n",
    "    for fold in range(4):\n",
    "        cls_model = YOLO(f'{data_path}/models/{model_name}/fold_{fold}_best.pt')\n",
    "        print(model_name, f'fold {fold}')\n",
    "        sub = predict_cls(df1, cls_model, batch_size=16)\n",
    "        sub = test1[['trustii_id','NAME']].merge(sub, on='NAME', how='left')\n",
    "        subs.append(sub)\n",
    "        backup.append(sub.copy())\n",
    "\n",
    "sub0 = subs[0]\n",
    "class_names = sub0.columns[-23:]\n",
    "sub0['bbox_count'] = sub0.groupby('NAME')['NAME'].transform('count')\n",
    "mask = sub0.bbox_count == 1\n",
    "probs = sub0.loc[mask, class_names].values\n",
    "for sub1 in subs[1:]:\n",
    "    sub1['bbox_count'] = sub1.groupby('NAME')['NAME'].transform('count')\n",
    "    mask2 = sub1.bbox_count == 1\n",
    "    probs += sub1.loc[mask2,class_names].values\n",
    "sub0['class_id'] = 0\n",
    "sub0.loc[mask, 'class_id'] = probs.argmax(axis=1)\n",
    "sub0.loc[mask, 'class'] = sub0.loc[mask, 'class_id'].apply(lambda x: class_names[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9OCvoDafCs6"
   },
   "outputs": [],
   "source": [
    "sub0 = sub0.reset_index(drop=True)\n",
    "cols = ['trustii_id', 'NAME', 'x1', 'y1', 'x2', 'y2', 'class']\n",
    "sub0[cols].to_csv(f'rerun_fix_test_aug1_crop_rotate_rotate50_avg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6493869,
     "sourceId": 10488322,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6494021,
     "sourceId": 10488596,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6494033,
     "sourceId": 10488617,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6494074,
     "sourceId": 10488691,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
